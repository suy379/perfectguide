{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 스태킹 앙상블"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cancer = load_breast_cancer()\n",
    "#dataset = pd.DataFrame(cancer.data, columns=cancer.feature_names)\n",
    "#dataset.head()\n",
    "\n",
    "X_df = cancer.data\n",
    "y_df = cancer.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_df, y_df, test_size=.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 기본 스태킹\n",
    "- 스태킹에 사용될 \"개별\" ML 알고리즘 모델들을 생성(여기서 사용되는 것은 KNN, RF, DT, Adaboost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#객체\n",
    "knn_clf = KNeighborsClassifier(n_neighbors=4)\n",
    "rf_clf = RandomForestClassifier(n_estimators=100, random_state=0)\n",
    "dt_clf = DecisionTreeClassifier()\n",
    "ada_clf = AdaBoostClassifier(n_estimators=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
       "          learning_rate=1.0, n_estimators=100, random_state=None)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#학습\n",
    "knn_clf.fit(X_train, y_train)\n",
    "rf_clf.fit(X_train, y_train)\n",
    "dt_clf.fit(X_train, y_train)\n",
    "ada_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#예측\n",
    "knn_pred = knn_clf.predict(X_test)\n",
    "rf_pred = rf_clf.predict(X_test)\n",
    "dt_pred = dt_clf.predict(X_test)\n",
    "ada_pred = ada_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "knn 정확도: 0.9211\n",
      "랜덤 포레스트 정확도: 0.9649\n",
      "DT 정확도: 0.9123\n",
      "에이다부스트 정확도: 0.9561\n"
     ]
    }
   ],
   "source": [
    "#평가(정확도)\n",
    "print('knn 정확도: {0:.4f}'.format(accuracy_score(y_test, knn_pred)))\n",
    "print('랜덤 포레스트 정확도: {0:.4f}'.format(accuracy_score(y_test, rf_pred)))\n",
    "print('DT 정확도: {0:.4f}'.format(accuracy_score(y_test, dt_pred)))\n",
    "print('에이다부스트 정확도: {0:.4f}'.format(accuracy_score(y_test, ada_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 114)\n"
     ]
    }
   ],
   "source": [
    "#나온 예측값들을 붙이고, 새로운 데이터로 생성!\n",
    "preds = np.array([knn_pred, rf_pred, dt_pred, ada_pred]) #이 각각은 1줄 array이므로 행 기준으로 붙여서 4줄 만듦(여러개니까 [] 괄호를 써야함)\n",
    "print(preds.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1,\n",
       "       0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1,\n",
       "       0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1,\n",
       "       0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0,\n",
       "       1, 0, 0, 1])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(114, 4)\n",
      "[[0 0 0 0]\n",
      " [1 1 1 1]\n",
      " [1 1 1 1]\n",
      " [0 1 1 1]\n",
      " [1 1 1 1]\n",
      " [1 1 1 1]\n",
      " [1 1 1 1]\n",
      " [1 1 1 1]\n",
      " [1 1 1 1]\n",
      " [1 1 1 1]\n",
      " [0 0 0 1]\n",
      " [1 1 1 1]\n",
      " [1 1 1 1]\n",
      " [0 0 0 0]\n",
      " [0 0 1 1]\n",
      " [0 0 0 0]\n",
      " [1 1 1 1]\n",
      " [0 0 0 0]\n",
      " [0 0 0 0]\n",
      " [0 0 0 0]\n",
      " [0 0 0 0]\n",
      " [0 0 0 0]\n",
      " [1 1 1 1]\n",
      " [1 1 1 1]\n",
      " [0 0 0 0]\n",
      " [1 1 1 1]\n",
      " [1 1 1 1]\n",
      " [1 0 0 0]\n",
      " [1 1 1 1]\n",
      " [0 0 0 0]\n",
      " [1 1 1 1]\n",
      " [0 0 0 0]\n",
      " [1 1 1 1]\n",
      " [0 0 0 0]\n",
      " [1 1 1 1]\n",
      " [0 0 0 0]\n",
      " [1 1 1 1]\n",
      " [0 0 0 0]\n",
      " [1 1 1 1]\n",
      " [0 0 0 0]\n",
      " [0 0 1 0]\n",
      " [1 1 1 1]\n",
      " [0 0 0 0]\n",
      " [1 1 1 1]\n",
      " [0 1 0 1]\n",
      " [0 0 0 0]\n",
      " [1 1 1 1]\n",
      " [1 1 1 1]\n",
      " [1 1 1 1]\n",
      " [0 0 0 0]\n",
      " [0 0 0 0]\n",
      " [1 0 0 0]\n",
      " [0 0 0 0]\n",
      " [1 1 1 1]\n",
      " [1 1 1 1]\n",
      " [1 1 1 1]\n",
      " [1 1 0 1]\n",
      " [1 1 1 1]\n",
      " [1 1 0 1]\n",
      " [0 0 0 0]\n",
      " [0 0 0 0]\n",
      " [0 0 0 0]\n",
      " [1 1 1 1]\n",
      " [1 1 1 1]\n",
      " [0 0 0 0]\n",
      " [1 1 0 0]\n",
      " [0 0 0 0]\n",
      " [0 0 0 0]\n",
      " [0 0 0 0]\n",
      " [1 1 1 1]\n",
      " [1 1 1 1]\n",
      " [0 0 0 0]\n",
      " [1 1 1 1]\n",
      " [1 1 1 1]\n",
      " [0 0 0 0]\n",
      " [1 1 1 1]\n",
      " [1 1 1 1]\n",
      " [1 1 1 1]\n",
      " [1 1 1 1]\n",
      " [1 1 1 1]\n",
      " [0 0 0 0]\n",
      " [0 0 0 0]\n",
      " [0 0 0 0]\n",
      " [1 1 1 1]\n",
      " [0 0 0 0]\n",
      " [1 1 1 1]\n",
      " [1 1 1 1]\n",
      " [1 1 1 1]\n",
      " [0 0 0 0]\n",
      " [0 0 0 0]\n",
      " [1 1 1 1]\n",
      " [0 0 0 1]\n",
      " [1 1 1 1]\n",
      " [0 0 0 0]\n",
      " [1 1 1 1]\n",
      " [1 1 1 1]\n",
      " [0 0 0 0]\n",
      " [1 1 1 1]\n",
      " [1 1 1 1]\n",
      " [1 1 1 1]\n",
      " [1 1 1 1]\n",
      " [1 1 1 1]\n",
      " [1 1 1 1]\n",
      " [1 1 0 1]\n",
      " [0 0 0 0]\n",
      " [1 1 1 1]\n",
      " [0 0 0 0]\n",
      " [0 1 1 1]\n",
      " [0 0 0 1]\n",
      " [0 0 1 0]\n",
      " [1 1 1 1]\n",
      " [0 0 0 0]\n",
      " [0 0 0 0]\n",
      " [1 1 1 1]]\n"
     ]
    }
   ],
   "source": [
    "pred = np.transpose(preds) #그리고 위의 것을 전치시키면 컬럼이 4개가 됨.\n",
    "print(pred.shape)\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 만든 4개 모델의 예측 결과를 합한 데이터 세트로 학습+예측하는 최종 모델 만들기(이건 로지스틱 모델로 생성)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최종 정확도: 0.9737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "#객체\n",
    "lr_final = LogisticRegression(C=10) #C는 regulization의 람다 값으로, 이 값이 작을수록 규제가 강화됨.\n",
    "#학습\n",
    "lr_final.fit(pred, y_test) ##train셋을 넣어야 하는데(원래는 fit(X_train, y_train)), 여기서 최종모델의 학습은 정답과 앞서 예측한 예측값들을 넣어 학습한다.(여기서 과적합 위험o)\n",
    "#예측\n",
    "final = lr_final.predict(pred) ##예측 또한 X_test가 아니라 예측한 예측값들임(과적합 위험o)\n",
    "#평가\n",
    "print('최종 정확도: {0:.4f}'.format(accuracy_score(y_test, final)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CV 세트 기반의 스태킹(과적합 방지)\n",
    "- 앞에서 한 기본 스태킹은 과적합 발생 위험이 있음(학습할때부터 정답 데이터(y_test)를 넣어서 학습하므로)\n",
    "- 과적합을 막는 이 cv 기반 스태킹을 더 많이 쓴다!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Step 1 : 개별 모델들에게 적용-최종 학습 데이터와 최종 테스트 데이터 뽑아내기(cv 이용)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#이 함수는 모델 1개당 1번씩 적용하는 함수, 여기서 나온 학습 및 테스트데이터는 모델 각각에서 나온 것을 모두 stack하여 \"최종\" 을 만들게 됨.\n",
    "\n",
    "def get_stacking_base_datasets(model, X_train, y_train, X_test, n_folds):\n",
    "    #지정된 k값만큼 kfold 생성\n",
    "    kf = KFold(n_splits=n_folds, shuffle=False, random_state=0)\n",
    "    #최종학습데이터/최종테스트데이터 초기화\n",
    "    train_fold_pred = np.zeros((X_train.shape[0],1)) #최종 학습 데이터 개수는 사실 X_train.shape[0] 개수랑 똑같이 나옴\n",
    "    test_pred = np.zeros((X_test.shape[0],n_folds)) #최종 테스트 데이터 개수는 n_fold 한 만큼 나오고, 나중에 이를 평균해야 함.\n",
    "    print(model.__class__.__name__, '  MODEL 시작 ')\n",
    "    \n",
    "    #train셋 대상으로 cv // test셋 대상으로 예측\n",
    "    for folder_counter, (train_index, valid_index) in enumerate(kf.split(X_train)):\n",
    "        print('\\t 폴드 세트: ', folder_counter, ' 시작 ')\n",
    "        X_tr = X_train[train_index]\n",
    "        y_tr = y_train[train_index]\n",
    "        X_te = X_train[valid_index]\n",
    "        \n",
    "        model.fit(X_tr, y_tr) #학습\n",
    "        train_fold_pred[valid_index, :] = model.predict(X_te).reshape(-1,1) #검증셋으로 예측하고 이것을 최종 학습 데이터 내에 저장.--cv개수만큼 stack.\n",
    "        test_pred[:, folder_counter] = model.predict(X_test) #X_test로 예측하고 이것을 최종 테스트 데이터 내에 저장.(앞에서 cv한 개수만큼)->나중에 평균\n",
    "        \n",
    "    #최종 테스트 데이터에 있는(cv 개수만큼 컬럼 있음) 것들 평균해서 컬럼 하나로 만들기\n",
    "    test_pred_mean = np.mean(test_pred, axis=1).reshape(-1,1)\n",
    "    \n",
    "    return train_fold_pred, test_pred_mean #최종 나오는 것은 '최종학습데이터'와 '최종테스트데이터'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier   MODEL 시작 \n",
      "\t 폴드 세트:  0  시작 \n",
      "\t 폴드 세트:  1  시작 \n",
      "\t 폴드 세트:  2  시작 \n",
      "\t 폴드 세트:  3  시작 \n",
      "\t 폴드 세트:  4  시작 \n",
      "\t 폴드 세트:  5  시작 \n",
      "\t 폴드 세트:  6  시작 \n",
      "RandomForestClassifier   MODEL 시작 \n",
      "\t 폴드 세트:  0  시작 \n",
      "\t 폴드 세트:  1  시작 \n",
      "\t 폴드 세트:  2  시작 \n",
      "\t 폴드 세트:  3  시작 \n",
      "\t 폴드 세트:  4  시작 \n",
      "\t 폴드 세트:  5  시작 \n",
      "\t 폴드 세트:  6  시작 \n",
      "DecisionTreeClassifier   MODEL 시작 \n",
      "\t 폴드 세트:  0  시작 \n",
      "\t 폴드 세트:  1  시작 \n",
      "\t 폴드 세트:  2  시작 \n",
      "\t 폴드 세트:  3  시작 \n",
      "\t 폴드 세트:  4  시작 \n",
      "\t 폴드 세트:  5  시작 \n",
      "\t 폴드 세트:  6  시작 \n",
      "AdaBoostClassifier   MODEL 시작 \n",
      "\t 폴드 세트:  0  시작 \n",
      "\t 폴드 세트:  1  시작 \n",
      "\t 폴드 세트:  2  시작 \n",
      "\t 폴드 세트:  3  시작 \n",
      "\t 폴드 세트:  4  시작 \n",
      "\t 폴드 세트:  5  시작 \n",
      "\t 폴드 세트:  6  시작 \n"
     ]
    }
   ],
   "source": [
    "#모델당 한번씩 위 함수 적용(n_folds=7 통일)\n",
    "knn_train, knn_test = get_stacking_base_datasets(knn_clf, X_train, y_train, X_test, 7)\n",
    "rf_train, rf_test = get_stacking_base_datasets(rf_clf, X_train, y_train, X_test, 7)\n",
    "dt_train, dt_test = get_stacking_base_datasets(dt_clf, X_train, y_train, X_test, 7)\n",
    "ada_train, ada_test = get_stacking_base_datasets(ada_clf, X_train, y_train, X_test, 7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Step 2 : 메타 모델에게 학습, 예측, 평가!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원본 train셋:  (455, 30) (455,)\n",
      "원본 test셋:  (114, 30)\n"
     ]
    }
   ],
   "source": [
    "#앞의 각 모델별로 최종학습데이터, 최종테스트데이터가 나왔는데 그것들 각각 stack해야됨.\n",
    "Stack_X_train = np.concatenate((knn_train, rf_train, dt_train, ada_train), axis=1)\n",
    "Stack_X_test = np.concatenate((knn_test, rf_test, dt_test, ada_test), axis=1)\n",
    "\n",
    "#잘됐는지 확인\n",
    "print('원본 train셋: ', X_train.shape, y_train.shape)\n",
    "print('원본 test셋: ', X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stack후 train셋:  (455, 4)\n",
      "stack후 test셋:  (114, 4)\n"
     ]
    }
   ],
   "source": [
    "print('stack후 train셋: ', Stack_X_train.shape)\n",
    "print('stack후 test셋: ', Stack_X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최종 메타 모델의 정확도: 0.9737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "#이제 메타 모델에게 학습, 예측, 평가를 시켜보자.\n",
    "#객체\n",
    "lr_final = LogisticRegression(C=10)\n",
    "#학습- stack_X_train과 y_train 넣고\n",
    "lr_final.fit(Stack_X_train, y_train)\n",
    "#예측-stack_X_test 넣고\n",
    "stack_final = lr_final.predict(Stack_X_test)\n",
    "#평가- 위의 예측값과 정답값(y_test)와 비교\n",
    "print('최종 메타 모델의 정확도: {0:.4f}'.format(accuracy_score(stack_final, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### stacking 방법은 분류뿐 아니라 회귀에서도 가능! (5장에서 실습)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
